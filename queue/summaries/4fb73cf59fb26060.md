Yes, OpenAI and Los Alamos National Laboratory have been collaborating on developing safety evaluations aimed at assessing and measuring biological capabilities and risks related to advanced frontier AI models. This collaboration focuses on ensuring that cutting-edge AI technologies are thoroughly evaluated for potential risks, including those pertaining to biosecurity and related fields. The goal is to create robust frameworks and tools that can identify, quantify, and mitigate possible misuse or unintended consequences arising from powerful AI systems, particularly in sensitive areas such as biology and biotechnology. This work is part of broader efforts within the AI research community to promote safe and responsible AI development.