It sounds like you're describing the improvements made with InstructGPT models! These models are indeed designed to better align with user intentions, producing outputs that are more truthful and less toxic compared to earlier models like GPT-3. This is achieved through training methods that incorporate human feedback, which helps the model learn preferred behaviors more effectively. By deploying InstructGPT as the default on the API, users benefit from more reliable and user-aligned AI interactions. If you want, I can provide more details on how this alignment training process works or the implications for different use cases!