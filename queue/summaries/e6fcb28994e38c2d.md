The paper with arXiv ID 2401.17435v5 addresses the challenge of predicting human choices in economic contexts, which is fundamental to areas like marketing, finance, and public policy but limited by scarcity of human choice data. Specifically, it investigates whether large language models (LLMs) can generate synthetic training data for this task using language-based persuasion games—a complex setting involving natural language and strategic interactions.

Key contributions and findings include:

- **Data generation with LLMs:** Models trained on data synthesized by LLMs effectively predict actual human decisions in language-based persuasion games, surpassing models trained on real human data.
  
- **Dual role of LLMs:** The study empirically explores LLMs’ capacity as both data generators and predictors, establishing a framework for leveraging LLMs in these dual roles for human choice prediction.

- **Insights into decision-making:** Analysis using the framework reveals that interaction history—not just linguistic sentiment—is critical for predicting choice behavior in repeated interactions.

- **Alignment of LLM and human decision patterns:** When LLMs capture history-dependent decision-making similarly to humans, their predictive accuracy substantially improves.

- **Robustness:** The results hold across various persuasion game scenarios, underscoring the broad applicability of LLM-generated data to model human decision-making.

Overall, this work highlights the promising potential of large language models to supplement or even replace human data for economic choice prediction tasks, particularly in complex, language-rich strategic environments.