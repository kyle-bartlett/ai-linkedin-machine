Yes, Cohere, OpenAI, and AI21 Labs have collaborated to develop a preliminary set of best practices aimed at guiding organizations that develop or deploy large language models (LLMs). These best practices focus on responsible AI development and deployment to ensure safety, fairness, transparency, and accountability. 

While the exact details of their joint guidelines may evolve, such best practices generally cover areas including:

1. **Safety and Robustness**: Ensuring models do not produce harmful or biased outputs and can handle unexpected inputs gracefully.

2. **Transparency**: Providing clear information about the capabilities and limitations of the models.

3. **Privacy**: Protecting user data and ensuring compliance with privacy regulations.

4. **Fairness and Bias Mitigation**: Actively working to minimize biases in training data and model behavior.

5. **Accountability**: Establishing processes for oversight, reporting issues, and enabling redress in case of harm.

6. **Collaboration**: Engaging with external researchers, organizations, and communities to improve model understanding and application.

If youâ€™d like, I can provide more detailed summaries or point you to resources where these best practices have been published.