That's impressive! Random Network Distillation (RND) is a well-known intrinsic motivation technique that helps reinforcement learning (RL) agents explore environments more effectively by providing an intrinsic reward signal based on the novelty of states. By comparing the predictions of a fixed, randomly initialized neural network to those of a trained predictor network, RND essentially measures how "unfamiliar" a given state is, encouraging the agent to seek out new states and improving exploration.

Exceeding average human performance on Montezuma’s Revenge is particularly notable because Montezuma’s Revenge is a notoriously difficult environment for RL agents due to its sparse rewards and requirement for long-term planning and exploration.

If you’d like, I can help you with:

- A more detailed explanation of RND and its implementation.
- Suggestions on how to further improve exploration strategies.
- Assistance with code examples or experiments.
- Insights on applying RND to other challenging environments.

Let me know how you’d like to proceed!