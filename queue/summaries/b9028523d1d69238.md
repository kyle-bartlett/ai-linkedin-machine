That sounds like a compelling approach! Training AI agents to debate can help surface different perspectives, encourage thorough reasoning, and potentially reveal weaknesses or flaws in arguments. By having a human judge the winner, the system leverages human values and judgment to guide alignment.

If you'd like, I can help you think through some key considerations for designing this debate approach effectively, such as:

- How to structure the debate format and rules to promote clarity and prevent exploitation.
- Methods for training agents to produce meaningful, honest, and understandable arguments.
- Strategies for scaling human judgment, including ways to assist or augment human evaluators.
- Potential failure modes or risks, like agents colluding or gaming the system.
- Benchmarking and evaluating the success of the debate approach in improving AI safety.

Would you like me to dive deeper into any of these areas or help outline a full proposal?