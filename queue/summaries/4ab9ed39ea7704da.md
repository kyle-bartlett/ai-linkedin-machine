The paper with arXiv ID 2511.16416v1 investigates whether supervised machine learning (ML) and deep learning (DL) models can distinguish between perceived lower-quality and higher-quality news articles. Key points from the study include:

- **Dataset:**  
  - 1,412,272 English news articles collected from the Common Crawl dataset covering years 2018 to 2024.  
  - Articles labeled at the website level with quality classes (low vs. high) based on expert consensus ratings of 579 news source websites, split at the median to form roughly equal class sizes (~706k articles each).  
  - Each article labeled with 194 linguistic features derived from the website-level data.

- **Models Tested:**  
  - **Traditional ML classifiers:** Included Random Forest, which achieved an accuracy of 0.7355 and ROC AUC of 0.8131.  
  - **Deep Learning classifiers:** Various BERT-based models.  
    - ModernBERT-large (context length 256): Best deep learning performance with accuracy 0.8744, ROC AUC 0.9593, and F1 score 0.8739.  
    - DistilBERT-base (context length 512): Accuracy 0.8685, ROC AUC 0.9554.  
    - DistilBERT-base (context length 256): Accuracy 0.8478, ROC AUC 0.9407.  
    - ModernBERT-base (256): Accuracy 0.8569, ROC AUC 0.9470.

- **Conclusions:**  
  - Both traditional ML and DL models can effectively differentiate perceived lower-quality versus higher-quality news articles on a large-scale global dataset.  
  - Deep learning BERT-based models outperform traditional classifiers but require more computational resources.  
  - Random Forest and other CPU-based classifiers still produce strong baseline results.

If you would like, I can provide more details about methodology, feature engineering, or specific results from the paper.