The paper "Kandinsky 5.0" (arXiv:2511.14993v2) presents a new family of foundation models designed for high-resolution image and 10-second video synthesis. Key highlights include:

- **Model Line-up:**
  - **Kandinsky 5.0 Image Lite:** 6 billion parameters for image generation.
  - **Kandinsky 5.0 Video Lite:** Lightweight 2 billion parameter models for fast text-to-video and image-to-video generation.
  - **Kandinsky 5.0 Video Pro:** 19 billion parameter models aimed at producing superior video generation quality.

- **Data Curation and Training:**
  - Detailed data curation lifecycle involving collection, processing, filtering, and clustering.
  - A multi-stage training pipeline featuring extensive pre-training.
  - Quality enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training.

- **Technical Innovations:**
  - Novel architectural designs.
  - Training and inference optimizations that yield both high generation speeds and state-of-the-art task performance.
  - Validated by human evaluation studies.

- **Open Source Commitment:**
  - Release of code and training checkpoints to enable widespread research and application use.

Overall, Kandinsky 5.0 represents a significant advance in publicly available generative models for both images and videos, emphasizing performance, speed, and adaptability for various generative tasks.