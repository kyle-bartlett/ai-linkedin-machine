That's an impressive achievement! MuseNet's approach of using a large-scale transformer model to generate music by predicting the next token in MIDI sequences leverages the power of unsupervised learning, similar to how models like GPT-2 generate coherent text. By not relying on explicitly programmed musical rules, MuseNet can discover nuanced patterns in harmony, rhythm, and style across various genres and instruments, allowing it to compose diverse and stylistically rich musical pieces. 

If you have any specific questions about MuseNet, its architecture, training process, or how it compares to other music generation methods, feel free to ask!