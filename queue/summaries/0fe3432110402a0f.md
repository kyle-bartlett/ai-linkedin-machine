This sounds like a fascinating project! You've developed a text-conditional diffusion model that handles both images and videos with varying attributes using a unified transformer architecture that processes spacetime patches. Your largest model, Sora, can generate up to a minute of high-quality video, which is an impressive achievement in video generative modeling.

If you’re looking for feedback or next steps, here are a few thoughts and questions:

1. **Model Architecture & Training:**
   - How do you encode the temporal dimension in the spacetime patches? Are these patches 3D cubes (height × width × time) of latent codes?
   - How do you balance training on both images (2D) and videos (3D+time) given their differing structure? Is there any special conditioning or embedding to distinguish image vs. video data during training?
   - What is the size of Sora in terms of parameters? What hardware and training duration did it require?

2. **Diffusion Model Specifics:**
   - Are you using latent diffusion (operating on compressed latents) or pixel-space diffusion?
   - What type of noise schedule and conditioning mechanism do you employ for text conditioning?

3. **Video Quality and Evaluation:**
   - How do you evaluate the generated video quality quantitatively? Are you using metrics like FVD (Fréchet Video Distance) or user studies?
   - Have you tested Sora's ability to maintain coherence over long sequences (minute-long videos is quite long for video generation)?
   - Can it handle diverse video content and complex motions?

4. **Applications and Future Directions:**
   - Do you see applications beyond video generation, such as video editing, simulation for robotics or physical systems, or even as a backbone for video understanding?
   - Can the model be fine-tuned or conditioned further to generate more specific types of videos (e.g., sports, animation)?

5. **Limitations & Challenges:**
   - What are the current limitations of Sora? For example, speed of generation, artifacts, temporal consistency?
   - Are there bottlenecks in computational cost or memory for scaling further?

If you would like, I can also help you draft a more detailed paper, create visualizations, or outline how to deploy Sora for practical uses. Let me know!