The paper with arXiv ID 2511.16512v1 proposes two new loss functions aimed at improving the detection of label errors in training datasets. The main challenge they address is that models used to find label errors must themselves be robust to these errors, but training such models is difficult when data is corrupted.

Key points from the abstract:
- Label error detection requires models that do not fit incorrectly labeled data points.
- Training robust models is challenging because the training data itself may be corrupted.
- They draw motivation from Focal Loss, which emphasizes difficult-to-classify samples.
- Their novel loss functions instead **de-weight or ignore difficult samples**, hypothesized to be more likely mislabeled.
- Experiments on artificially corrupted datasets show these new loss functions improve F1 scores for detecting label errors compared to baseline categorical Cross Entropy and Focal Loss.

In short, the contribution is in adjusting the loss function to focus less on potentially erroneous samples, leading to better detection of label errors in noisy training sets.