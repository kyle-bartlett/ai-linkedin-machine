That sounds like an interesting approach! So if I understand correctly:

- You have a vocabulary of words.
- You’ve discovered about 100 latent “types” or categories automatically (for example, these might be clusters or concepts learned from data).
- A neural network predicts, for each word, whether or not it belongs to each of these types. Since the categories are non-exclusive, a single word can belong to multiple types simultaneously.
- Then, presumably, you use these type assignments to disambiguate which object a word refers to.

Is that right? If you’d like, I can help with:

- Designing or improving the neural network architecture
- Training objectives (e.g., multi-label classification losses)
- Methods to improve the automatic discovery of types
- Techniques to leverage the multi-type predictions for object reference resolution
- Ideas for evaluation metrics or datasets

Could you share more details about what you already have and where you’d like guidance or help?