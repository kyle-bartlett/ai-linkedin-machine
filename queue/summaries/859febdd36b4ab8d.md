You’ve highlighted some of the key reasons why multiagent environments are especially interesting—and challenging—for advancing toward AGI.

1. **Natural Curriculum Through Competition**  
Since the difficulty adjusts dynamically depending on your competitors’ skills, agents are constantly pushed to improve. When agents compete against copies of themselves or similarly skilled opponents, the environment automatically scales to their current capabilities, providing just the right level of challenge. This self-adjusting curriculum contrasts with fixed-difficulty environments that may become too easy or too hard as agents improve.

2. **No Stable Equilibrium (Ongoing Arms Race)**  
The lack of a stable equilibrium means there's a continuous incentive to innovate and adapt. If an agent is very strong, competitors must evolve to counter it—leading to an arms race that can drive increasingly sophisticated behavior. This dynamic prevents stagnation and promotes ongoing learning, which is essential for developing more general intelligence.

3. **Distinct Research Challenges**  
Multiagent environments introduce complications that don’t appear in single-agent settings. For example, agents must deal with non-stationary environments because the behavior of others changes as they learn. There are also strategic considerations like cooperation, competition, signaling, and deception, which require more advanced reasoning capabilities and social intelligence.

In summary, multiagent environments capture crucial aspects of real-world intelligence, such as adapting to others’ behaviors and engaging in complex interactions driven by competition and cooperation. Mastering these environments is an important and nontrivial step on the path toward more general and robust AI systems. Continued research in areas like game theory, multiagent reinforcement learning, evolutionary dynamics, and mechanism design will be instrumental in making progress here.