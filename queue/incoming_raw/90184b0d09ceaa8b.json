{
  "source": "OpenAI Blog",
  "title": "Testing robustness against unforeseen adversaries",
  "url": "https://openai.com/index/testing-robustness",
  "published": "Thu, 22 Aug 2019 07:00:00 GMT",
  "summary_raw": "We\u2019ve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen\u00a0attacks.",
  "ingested_at": "2025-11-21 05:43:48.570800"
}