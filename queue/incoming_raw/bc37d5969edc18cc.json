{
  "source": "OpenAI Blog",
  "title": "CLIP: Connecting text and images",
  "url": "https://openai.com/index/clip",
  "published": "Tue, 05 Jan 2021 08:00:00 GMT",
  "summary_raw": "We\u2019re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the \u201czero-shot\u201d capabilities of GPT-2 and\u00a0GPT-3.",
  "ingested_at": "2025-11-21 05:43:48.567922"
}