{
  "source": "OpenAI Blog",
  "title": "AI and efficiency",
  "url": "https://openai.com/index/ai-and-efficiency",
  "published": "Tue, 05 May 2020 07:00:00 GMT",
  "summary_raw": "We\u2019re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet\u00a0classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet\u00a0(by contrast, Moore\u2019s Law\u00a0would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware\u00a0efficiency.",
  "ingested_at": "2025-11-21 05:43:48.569070"
}