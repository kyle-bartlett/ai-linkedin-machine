{
  "source": "Arxiv Machine Learning",
  "title": "A Distributionally Robust Framework for Nuisance in Causal Effect Estimation",
  "url": "https://arxiv.org/abs/2505.17717",
  "published": "Fri, 21 Nov 2025 00:00:00 -0500",
  "summary_raw": "arXiv:2505.17717v2 Announce Type: replace-cross \nAbstract: Causal inference requires evaluating models on balanced distributions between treatment and control groups, while training data often exhibits imbalance due to historical decision-making policies. Most conventional statistical methods address this distribution shift through inverse probability weighting (IPW), which requires estimating propensity scores as an intermediate step. These methods face two key challenges: inaccurate propensity estimation and instability from extreme weights. We decompose the generalization error to isolate these issues--propensity ambiguity and statistical instability--and address them through an adversarial loss function. Our approach combines distributionally robust optimization for handling propensity uncertainty with weight regularization based on weighted Rademacher complexity. Experiments on synthetic and real-world datasets demonstrate consistent improvements over existing methods.",
  "ingested_at": "2025-11-21 05:43:50.701004"
}